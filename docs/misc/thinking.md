
# Thinking

## AI模型

AI模型可以理解为一个复杂的函数`f(x)`，模型的训练和微调目的是为了确保输入可以得到最优的解。<br>
模型的运行与传统数学软件、计算机程序有所不同，对于计算资源和架构有一定的要求，GPU等支持并行计算的系统比较适合。

因此模型一般涉及如下几个方面：

1. 模型的架构设计
2. 数据集准备
3. 模型训练
4. 模型微调
5. 模型量化

GPT是一个语言模型，更擅长自然语言处理，不适合做真正的深度计算（比如，物理学中的某种模型计算）。

GPT由多层神经网络构成，通过`word embedding`将词语转换成高维的向量坐标，这样只能处理数字的神经网络层也可以处理人类的语言。

每一层对于这些向量进行加权求和再传递给下一层，直至最后输出。

比如手写数字的识别，0-9这10个数字，每个数字图像转换成1维的灰度向量。将其输入给模型，模型的输出为10个数字，每个数字代表结果分别是0-9的概率。

经过一定的后处理，我们就可以获得一个基于模型的手写数字识别软件。

GPT等模型采用前馈网络，将输入单向地在多层神经网络中向前传递计算，直至最终的输出，再重新“审视”当前的整个句子调整输出，以此迭代下去，直至结束。<br>
这与人脑的处理是有相似和差异的，人脑也会激活相关的神经元，但是它以我们不可名状的方式综合处理得到结果，而不是GPT这样机械地重复上述前馈网络机制的这个过程。

通过Google的Attention Is All You Need这篇论文，OpenAI加入了注意力机制。在处理我们输入的句子中，它也会借鉴人类的处理机制，提取句子中的重点词语，从而能够处理长文本。<br>
通过强化学习的方案，开发人员训练出一个奖励模型来监督调教GPT的模型训练。

## AI将编程的表达能力向问题域迈进一大步

在编译原理的书里提到，编译器的作用是用来填补问题域和实现域的鸿沟：我们使用编程语言来描述问题的解决方案，编译器将我们的代码来转换成可以在计算机中运行的特定格式文件。
如果一门语言的表达能力越接近实现域（比如，C语言），越需要程序员来进行大量的抽象设计，程序员的工作量越大。
当编程语言的表达能力越抽象，越接近实际问题时（比如，Python），背后的编译器/解释器承担的工作越多。

而如今，LLM使得自然语言可以成为描述问题解决方案的“编程语言”，大模型的工作流是背后的“编译器”。

## 数学成绩不好是因为缺乏数学天赋吗？

今天看了B站3b1b的[视频](https://www.bilibili.com/video/BV1ksuwzjE52/?spm_id_from=333.788.recommend_more_video.16&trackid=web_related_0.router-related-2206146-rwzvg.1767626464492.895&vd_source=f25b212ec8ec63986b0023ead1130532)，关于学数学是否靠天赋。他的观点更倾向于去衡量对于数学学习的准备程度，很多同学表现的反应迅速，是因为他们已经有了足够的预备知识和经历。

回顾了一下我自己的学习历程，我的糟糕体验和做的不好的地方在于：

1. 不该在课堂因为某个知识点去推导公式，导致错过了后续的内容。
2. 因为没有提前预习或者了解潜在、隐性的预备知识，导致上课时无法跟上老师的节奏，从而会走神。
3. 因为没有经历过数学竞赛的训练，小学数学竞赛考了0分，觉得自己不具备数学天赋。
4. 遇到挫折时，会归因自己不具备天赋而不去审视预备知识的准备。
5. 没有去找其他的资料，我是很好奇数学概念背后的故事和目的的，但是当时也没有去图书馆努力搜寻。
6. 跟老师交流少，有些题目起初会正向去解，中间卡壳时靠着猜和直觉去做，有时候会蒙对，导致成绩不稳定。事后也没有找老师请教。

总体上，我觉得我至今遇到的挑战还不足以归因为天赋的问题，更多的因为我没有准备好。当然，我的数学天赋可能也确实不高。
不过，我也不是那么笨的人，高考数学（低于140）和高数的成绩(低于100)可以说明我的智商没那么差~

[【大师课】[中英字幕]数学天才 陶哲轩Terence Tao 不再恐惧数学 学会新思维](https://www.bilibili.com/video/BV1wa41187Wf/?spm_id_from=333.788.recommend_more_video.1&trackid=web_related_0.router-related-2206146-7vfnq.1767626510207.951&vd_source=f25b212ec8ec63986b0023ead1130532)

---